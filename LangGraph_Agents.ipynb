{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Getting Started\n",
        "This notebook provides a basic introduction to building a LangGraph, a framework for creating complex conversational AI agents. It covers a basic conversational loop where the assistant generates a response, a condition checks if a tool is needed, and if so, a tool is invoked, and its output is fed back to the assistant. The visualization helps in understanding this flow and the decision points within the graph."
      ],
      "metadata": {
        "id": "7cfx_hqytYPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain-google-genai google-generativeai langgraph langchain_community ddgs"
      ],
      "metadata": {
        "id": "5R79mrnev8CV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.agents import initialize_agent\n",
        "from typing import Annotated\n",
        "from langchain_core.tools import tool, InjectedToolCallId\n",
        "from langgraph.prebuilt import InjectedState\n",
        "from langgraph.graph import StateGraph, START, MessagesState\n",
        "from langgraph.types import Command\n",
        "\n",
        "# Get the API key from Colab secrets\n",
        "API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# Configure the genai library with the API key\n",
        "genai.configure(api_key=API_KEY)"
      ],
      "metadata": {
        "id": "vd5AGDwWwODE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Authenticate your notebook environment (Colab only)"
      ],
      "metadata": {
        "id": "RtdvBMOLgNj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "VPs8Z4zrxC8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test your API Key"
      ],
      "metadata": {
        "id": "aMeX3yFvgRVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", google_api_key=API_KEY)\n",
        "try:\n",
        "    response = llm.invoke(\"What is LLM?\")\n",
        "    print(response)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "id": "20uEGaIRwG5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a Search Tool"
      ],
      "metadata": {
        "id": "SwQQ90WNvb_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "def search_tool(prompt: str)->str:\n",
        "  \"Performs Search using DuckDuckGo\"\n",
        "  search = DuckDuckGoSearchRun()\n",
        "  text=search.invoke(prompt)\n",
        "  return text\n"
      ],
      "metadata": {
        "id": "AEpEB4WaalkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_tool(\"What is capital city of India ?\")"
      ],
      "metadata": {
        "id": "u9gtxHU_cIVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a Reserach Agent"
      ],
      "metadata": {
        "id": "03r5QKs1vhLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "# The 'create_react_agent' function in LangGraph's pre-built templates provides\n",
        "# a streamlined way to create a ReAct agent. ReAct (Reasoning and Acting) is a popular framework\n",
        "# for building agents that can interact with tools.\n",
        "# This function encapsulates the core components and logic needed to set up such an agent.\n",
        "research_agent = create_react_agent(llm, tools=[search_tool], prompt=\"You are a researcher. DO NOT do any math.\",name=\"research_agent\")"
      ],
      "metadata": {
        "id": "C6kF0ceBdcnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import convert_to_messages\n",
        "\n",
        "\n",
        "def pretty_print_message(message, indent=False):\n",
        "    pretty_message = message.pretty_repr(html=True)\n",
        "    if not indent:\n",
        "        print(pretty_message)\n",
        "        return\n",
        "\n",
        "    indented = \"\\n\".join(\"\\t\" + c for c in pretty_message.split(\"\\n\"))\n",
        "    print(indented)\n",
        "\n",
        "\n",
        "def pretty_print_messages(update, last_message=False):\n",
        "    is_subgraph = False\n",
        "    if isinstance(update, tuple):\n",
        "        ns, update = update\n",
        "        # skip parent graph updates in the printouts\n",
        "        if len(ns) == 0:\n",
        "            return\n",
        "\n",
        "        graph_id = ns[-1].split(\":\")[0]\n",
        "        print(f\"Update from subgraph {graph_id}:\")\n",
        "        print(\"\\n\")\n",
        "        is_subgraph = True\n",
        "\n",
        "    for node_name, node_update in update.items():\n",
        "        update_label = f\"Update from node {node_name}:\"\n",
        "        if is_subgraph:\n",
        "            update_label = \"\\t\" + update_label\n",
        "\n",
        "        print(update_label)\n",
        "        print(\"\\n\")\n",
        "\n",
        "        messages = convert_to_messages(node_update[\"messages\"])\n",
        "        if last_message:\n",
        "            messages = messages[-1:]\n",
        "\n",
        "        for m in messages:\n",
        "            pretty_print_message(m, indent=is_subgraph)\n",
        "        print(\"\\n\")"
      ],
      "metadata": {
        "id": "m1rHwxRbQxce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Research Agent"
      ],
      "metadata": {
        "id": "xt03nd3Nvpnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in research_agent.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is Capital City of India ?\"}]}\n",
        "):\n",
        "    pretty_print_messages(chunk)"
      ],
      "metadata": {
        "id": "h4j6aE0KQ1B3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Python Functions as tools"
      ],
      "metadata": {
        "id": "Yw7AF_ORvo0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add(a: float, b: float):\n",
        "    \"\"\"Add two numbers.\"\"\"\n",
        "    return a + b\n",
        "\n",
        "\n",
        "def multiply(a: float, b: float):\n",
        "    \"\"\"Multiply two numbers.\"\"\"\n",
        "    return a * b\n",
        "\n",
        "\n",
        "def divide(a: float, b: float):\n",
        "    \"\"\"Divide two numbers.\"\"\"\n",
        "    return a / b\n"
      ],
      "metadata": {
        "id": "amkBP65WRdgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Math Agent"
      ],
      "metadata": {
        "id": "VDsxlevsv1gl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "math_agent = create_react_agent(\n",
        "    model=llm,\n",
        "    tools=[add, multiply, divide],\n",
        "    prompt=(\n",
        "        \"You are a math agent.\\n\\n\"\n",
        "        \"INSTRUCTIONS:\\n\"\n",
        "        \"- Assist ONLY with math-related tasks\\n\"\n",
        "        \"- After you're done with your tasks, respond to the supervisor directly\\n\"\n",
        "        \"- Respond ONLY with the results of your work, do NOT include ANY other text.\"\n",
        "    ),\n",
        "    name=\"math_agent\",\n",
        ")"
      ],
      "metadata": {
        "id": "RN-jGL5jv17J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Match Agent"
      ],
      "metadata": {
        "id": "phhPvAF2v7BA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in math_agent.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"what's (3 + 5) x 7\"}]}\n",
        "):\n",
        "    pretty_print_messages(chunk)"
      ],
      "metadata": {
        "id": "ZVlVvrk0RpxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Agents as Tools for Supervisor Agent"
      ],
      "metadata": {
        "id": "477N5oteglkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_handoff_tool(*, agent_name: str, description: str | None = None):\n",
        "    name = f\"transfer_to_{agent_name}\"\n",
        "    description = description or f\"Ask {agent_name} for help.\"\n",
        "\n",
        "    @tool(name, description=description)\n",
        "    def handoff_tool(\n",
        "        state: Annotated[MessagesState, InjectedState],\n",
        "        tool_call_id: Annotated[str, InjectedToolCallId],\n",
        "    ) -> Command:\n",
        "        tool_message = {\n",
        "            \"role\": \"tool\",\n",
        "            \"content\": f\"Successfully transferred to {agent_name}\",\n",
        "            \"name\": name,\n",
        "            \"tool_call_id\": tool_call_id,\n",
        "        }\n",
        "        return Command(\n",
        "            goto=agent_name,\n",
        "            update={**state, \"messages\": state[\"messages\"] + [tool_message]},\n",
        "            graph=Command.PARENT,\n",
        "        )\n",
        "\n",
        "    return handoff_tool"
      ],
      "metadata": {
        "id": "3WZGkPJLR5ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handoffs\n",
        "assign_to_research_agent = create_handoff_tool(\n",
        "    agent_name=\"research_agent\",\n",
        "    description=\"Assign task to a researcher agent.\",\n",
        ")\n",
        "\n",
        "assign_to_math_agent = create_handoff_tool(\n",
        "    agent_name=\"math_agent\",\n",
        "    description=\"Assign task to a math agent.\",\n",
        ")"
      ],
      "metadata": {
        "id": "t_HpP-eQTDpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building Supervisor Agent"
      ],
      "metadata": {
        "id": "exBq1B1xwbm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "supervisor_agent = create_react_agent(\n",
        "    model=llm,\n",
        "    tools=[assign_to_research_agent, assign_to_math_agent],\n",
        "    prompt=(\n",
        "        \"You are a supervisor managing two agents:\\n\"\n",
        "        \"- a research agent. Assign research-related tasks to this agent\\n\"\n",
        "        \"- a math agent. Assign math-related tasks to this agent\\n\"\n",
        "        \"Assign work to one agent at a time, do not call agents in parallel.\\n\"\n",
        "        \"Do not do any work yourself.\"\n",
        "    ),\n",
        "    name=\"supervisor\",\n",
        ")"
      ],
      "metadata": {
        "id": "H_IyI9VATJfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining the Graph"
      ],
      "metadata": {
        "id": "0BY7cWgJ4LVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END\n",
        "\n",
        "# Define the multi-agent supervisor graph\n",
        "supervisor = (\n",
        "    StateGraph(MessagesState)\n",
        "    # NOTE: `destinations` is only needed for visualization and doesn't affect runtime behavior\n",
        "    .add_node(supervisor_agent, destinations=(\"research_agent\", \"math_agent\", END))\n",
        "    .add_node(research_agent)\n",
        "    .add_node(math_agent)\n",
        "    .add_edge(START, \"supervisor\")\n",
        "    # always return back to the supervisor\n",
        "    .add_edge(\"research_agent\", \"supervisor\")\n",
        "    .add_edge(\"math_agent\", \"supervisor\")\n",
        "    .compile()\n",
        ")"
      ],
      "metadata": {
        "id": "mDzn8Qn6TNVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Image\n",
        "\n",
        "display(Image(supervisor.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "id": "XIUBpKxJTT8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test the Agent"
      ],
      "metadata": {
        "id": "SlTM0H7I4QGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in supervisor.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"find US and New York state GDP in 2024. what % of US GDP was New York state?\",\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "):\n",
        "    pretty_print_messages(chunk, last_message=True)\n",
        "\n",
        "final_message_history = chunk[\"supervisor\"][\"messages\"]"
      ],
      "metadata": {
        "id": "d4n9V6BsTnL_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}